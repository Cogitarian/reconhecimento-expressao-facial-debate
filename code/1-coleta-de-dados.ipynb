{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coleta de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse script usa a [API de reconhecimento facial da Microsoft](https://azure.microsoft.com/services/cognitive-services/face/) para detectar rostos e reconhecer a expressão facial dos candidatos durante o debate realizado pelo Estadão/TV Gazeta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import re\n",
    "import requests\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. OpenCV - dividir vídeo em frames\n",
    "O primeiro passo é usar o pacote [OpenCV](https://opencv.org/) para ler o vídeo e dividir em frames. O código é uma adaptação [deste](https://gist.github.com/keithweaver/70df4922fec74ea87405b83840b45d57), de autoria do usuário [keithweaver](https://gist.github.com/keithweaver) no GitHub. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_into_frames(fp, out, save_rate, preffix):\n",
    "    '''\n",
    "    INPUT:\n",
    "        fp = path to the video file\n",
    "    OUTPUT:\n",
    "        out = directory of the image output\n",
    "    PARAMS:\n",
    "        save_rate = save frame as img every x seconds\n",
    "        preffix = preffix of the filename\n",
    "    '''\n",
    "# Playing video from file:\n",
    "    cap = cv2.VideoCapture(fp)\n",
    "    fps = round(cap.get(cv2.CAP_PROP_FPS))\n",
    "    try:\n",
    "        if not os.path.exists(out):\n",
    "            os.makedirs(out)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory for output')\n",
    "    \n",
    "    currentFrame = 0\n",
    "    while(True):\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        ms = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "        currentFname = ms_to_hms(ms)\n",
    "        # Break condition\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Save only some specific frames\n",
    "        if (currentFrame % (fps * save_rate) == 0):    \n",
    "            # Saves image of the current frame in jpg file\n",
    "            filename = out + preffix + '-' + str(currentFname) + '.jpg'\n",
    "            #print ('Creating...' + filename)\n",
    "            cv2.imwrite(filename, frame)\n",
    "\n",
    "        # To stop duplicate images\n",
    "        currentFrame += 1\n",
    "\n",
    "        # Waits 1 second, then moves on to the next framw\n",
    "        \n",
    "    # When everything done, release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também definimos uma função auxiliar que converte um número de milisegundos para uma string no formato hora:minuto:segundo. Ela será usada na função abaixo para salvar o arquivo com a posição do vídeo já embutida no nome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ms_to_hms(ms):\n",
    "    '''\n",
    "    INPUT:\n",
    "        ms = an arbitrary number of milliseconds\n",
    "    OUTPUT:\n",
    "        hms = a string derived from the milliseconds \n",
    "        and formatted in a hh:mm:ss pattern\n",
    "    '''\n",
    "    s = str(int((ms/1000)%60)) + 's'\n",
    "    m = str(int((ms/(1000*60))%60)) + 'm'\n",
    "    h = str(int((ms/(1000*60*60))%24)) + 'h'\n",
    "    hms = [h, m, s]\n",
    "    hms = [i.zfill(3) for i in hms]\n",
    "    hms = '-'.join(hms)\n",
    "    return hms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, rodamos a função com os parâmetros desejados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = \"../data/imgs/frames/debate-tv-gazeta/\"\n",
    "fps = glob.glob(\"../data/video/debate-tv-gazeta/camera*.mp4\")\n",
    "for fp in fps:\n",
    "    print('Splitting', fp)\n",
    "    pat = re.match('.*(camera\\d).mp4', fp)[1]\n",
    "    split_into_frames(fp, out, 1, pat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Analisa imagens usando API da Microsoft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Credencial de acesso\n",
    "key = \"INSIRA SUA CHAVE AQUI\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função abaixo cria um *grupo facial*, a partir do qual a API consegue identificar a quem pertence cada rosto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_face_group(key, face_list_id):\n",
    "# This fucntion sends a put request that creates a face list using Microsoft API\n",
    "    url = \"https://brazilsouth.api.cognitive.microsoft.com/face/v1.0/facelists/\" + face_list_id\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Ocp-Apim-Subscription-Key': key,\n",
    "        }\n",
    "    data = {\n",
    "        'name':face_list_id,\n",
    "        'userData':'Sample faces of 2018 Brasil presidential candidates'\n",
    "    }\n",
    "    response = requests.put(url, json=data, headers=headers)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_list_id = 'candidatos-presidente-2018'\n",
    "make_face_group(key, face_list_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, adicionamos uma imagem clara do rosto de cada candidato no grupo facial criado anteriormente. Armazenamos a correspondência entre o id gerado pela API e o nome de cada candidato em um dicionário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_face(key, fp, face_list_id, dict_object):\n",
    "# This function takes sample faces and stores them in the face list.\n",
    "# By doing this, we will be able to identify the faces that we capture in the frame.\n",
    "# We also store the correspondences locally, so we can match them to a human-readable description\n",
    "# whithout the need to send another request.\n",
    "    \n",
    "    # Gets the name of the person using a regex pattern\n",
    "    name = re.search(\"(\\w+).jpg\", fp)\n",
    "    name = name.group(1)\n",
    "\n",
    "    # Reads the file as a binary object\n",
    "    image_data = open(fp, \"rb\").read()\n",
    "    \n",
    "    headers = {\n",
    "        # Request headers\n",
    "        'Content-Type': 'application/octet-stream',\n",
    "        'Ocp-Apim-Subscription-Key': key,\n",
    "    }\n",
    "    \n",
    "    params = {\n",
    "        # Request parameters\n",
    "        'userData': name\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "    \"url\": image_data\n",
    "    }\n",
    "    \n",
    "    # Parse the params as a string\n",
    "    query = ''\n",
    "    for k,v in params.items():\n",
    "        string = k + '=' + v + '&'\n",
    "        query += string\n",
    "    query = query[:-1]\n",
    "    \n",
    "    # Sends request and parses as json\n",
    "    url = \"https://brazilsouth.api.cognitive.microsoft.com/face/v1.0/facelists/\" + face_list_id + \"/persistedFaces?\" + query    \n",
    "    response = requests.post(url, params=params, headers=headers, data=image_data)\n",
    "    response = response.json()\n",
    "    persistedFaceId = response['persistedFaceId']\n",
    "    # Saves correspondence to a local dict\n",
    "    dict_object[persistedFaceId] = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fps = glob.glob('../data/imgs/control/*.jpg')\n",
    "face_dict = {}\n",
    "for fp in fps:\n",
    "     add_face(key, fp, face_list_id, face_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As próximas funções são usadas para passar as imagens para a API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta recebe um id temporário, gerado pela Microsoft ao receber uma foto. Ela então compara este rosto com os que estão armazenados no grupo facial, identificando de quem se trata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def identify_face(key, face_id, face_list_id):\n",
    "# This function takes an temporary face_id and matches it with the permanents ids in the face_list\n",
    "    try:\n",
    "        url = \"https://brazilsouth.api.cognitive.microsoft.com/face/v1.0/findsimilars/\"\n",
    "\n",
    "        headers = {\n",
    "            # Request headers\n",
    "            'Content-Type': 'application/json',\n",
    "            'Ocp-Apim-Subscription-Key': key,\n",
    "        }\n",
    "\n",
    "        data = {\n",
    "        \"faceId\": face_id,\n",
    "        \"faceListId\": face_list_id,\n",
    "        \"maxNumOfCandidatesReturned\": 1,\n",
    "        \"mode\": \"matchFace\"\n",
    "        }\n",
    "\n",
    "        response = requests.post(url, headers=headers, json=data)\n",
    "        if response.status_code != 200:\n",
    "            persisted_face_id = 'no_match'\n",
    "        else:\n",
    "            response = response.json()\n",
    "            persisted_face_id = response[0]['persistedFaceId']\n",
    "\n",
    "        return persisted_face_id\n",
    "    except:\n",
    "        print(\"Exception\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A próxima função passa todos os rostos encontrados em uma imagem para a função `identify_face()` e salva o output para um arquivo json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def identify(key, faces, face_list_id, timestamp, timeout):\n",
    "    # This function takes all the faces detected in a single image, passes it to identifiy_face() and saves the output as a JSON file.\n",
    "    try:\n",
    "        # Takes the timestamp from the fp string\n",
    "        timestamp = re.search(\"\\d{2}h\\-\\d{2}m\\-\\d{2}s\", fp)\n",
    "        timestamp = timestamp.group(0)\n",
    "        # For each face detected in the image\n",
    "        for face in faces:\n",
    "            # Add the timestamp data into the object\n",
    "            face['timestamp'] = timestamp\n",
    "\n",
    "            # Now e need to match the temporary face_id with the persistent face_id\n",
    "            face_id = face[\"faceId\"]\n",
    "            # Waits timeout so we don't burn all our requests/minute \n",
    "            time.sleep(timeout)        \n",
    "            # Sends request\n",
    "            permanent_id = identify_face(key, face_id, face_list_id)\n",
    "            face['permanentId'] = permanent_id\n",
    "            # Now we use the dict to get an actual face\n",
    "            if permanent_id != 'no_match':\n",
    "                name = face_dict[permanent_id]\n",
    "                face['name'] = name\n",
    "            else:\n",
    "                name = 'no_match'\n",
    "                face['name'] = 'no_match'\n",
    "\n",
    "            # Write to json\n",
    "            # If there is no file for this person, create it\n",
    "            filename = '../data/jsons/debate-tv-gazeta/' + name + '-' + timestamp + '.json'\n",
    "            #print(filename)\n",
    "            with open(filename, mode='w', encoding='utf-8') as f:\n",
    "                json.dump(face, f)\n",
    "    except:\n",
    "        print('Exception')\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa função recebe uma imagem, identifica os rostos presentes e passa para a função `identify()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_api(key, fp, face_dict, timeout):\n",
    "# This tunction takes a filepath to an image, runs the face recognition api on it\n",
    "# and stores the retrieved data in an array inside the given dictionary\n",
    "    try:\n",
    "       # Takes the timestamp from the fp string\n",
    "        timestamp = re.search(\"\\d{2}h\\-\\d{2}m\\-\\d{2}s\", fp)\n",
    "        timestamp = timestamp.group(0)\n",
    "        #print(timestamp)\n",
    "\n",
    "        # Reads the file as a binary object\n",
    "        image_data = open(fp, \"rb\").read()\n",
    "\n",
    "        # Defines parameters and sends request to API\n",
    "        headers = {'Ocp-Apim-Subscription-Key': key,\n",
    "               'Content-Type': 'application/octet-stream'}\n",
    "        params = {\n",
    "            'returnFaceId': 'true',\n",
    "            'returnFaceLandmarks': 'false',\n",
    "            'returnFaceAttributes': 'age,gender,headPose,smile,facialHair,glasses,' +\n",
    "            'emotion,hair,makeup,occlusion,accessories,blur,exposure,noise'\n",
    "        }\n",
    "        data = {'url': image_data}\n",
    "        url = \"https://brazilsouth.api.cognitive.microsoft.com/face/v1.0/detect\"\n",
    "        response = requests.post(url, params=params, headers=headers, json=data, data=image_data)\n",
    "        faces = response.json()\n",
    "\n",
    "        # Waits and sends request to the face identification routine\n",
    "        time.sleep(timeout)\n",
    "        identify(key, faces, face_list_id, timestamp, timeout)\n",
    "    except Exception as e:\n",
    "        print(\"Error on file\", timestamp)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files = glob.glob(\"../data/imgs/frames/debate-tv-gazeta/*.jpg\")\n",
    "timeout = .1 \n",
    "for fp in files:\n",
    "     run_api(key, fp, face_dict, timeout)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Concatena jsons em um único array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, lemos o output salvo por run_api() arquivo por aqui e montamos um único array com todos eles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concatenate_jsons(array):\n",
    "    files = glob.glob(\"../data/jsons/debate-tv-gazeta/*.json\")\n",
    "    for file in files:\n",
    "         with open(file) as f:\n",
    "            data = json.load(f)\n",
    "            array.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "array = []\n",
    "concatenate_jsons(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Cria um dataframe linear com os campos desejados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois, criamos um dataframe do Pandas a partir desse array e salvamos em um arquivo CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['name', 'timestamp', 'anger', 'contempt', 'disgust', 'fear', 'happiness', 'neutral', 'sadness', 'surprise', 'blur']\n",
    "df = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def array_to_df(array, df):\n",
    "    for item in array:        \n",
    "        row = {label:None for label in df.columns}\n",
    "        row['name'] = item['name']\n",
    "        row['timestamp'] = item['timestamp']\n",
    "        row['blur'] = item['faceAttributes']['blur']['value']\n",
    "        \n",
    "        for k,v in item['faceAttributes']['emotion'].items():\n",
    "            row[k] = v\n",
    "        \n",
    "        #print(row)\n",
    "        df = df.append(row, ignore_index=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = array_to_df(array, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Puts into chronological order and changes index\n",
    "df = df.sort_values(by='timestamp').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saves with a timestamp\n",
    "now = str(datetime.now())[:-7]\n",
    "now = now.replace(' ','_')\n",
    "now = now.replace(\":\",\"-\")\n",
    "df.to_csv(\"../data/output_files/debate-gazeta/api_output_\" + now + \".csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
